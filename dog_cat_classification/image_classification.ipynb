{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog, Cat Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Download dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1 - For this first you need to downlaod the Kaggel API (kaggle.json file) from your kaggle account. Then put that Kaggle.jason file in .kaggle folder in you PC. After this step run the folowing code to download dataset directly from kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Make sure to install kaggle libray [pip install kaggle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs-vs-cats.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "#download dataset from kaggle, using Kaggle API\n",
    "\n",
    "!kaggle datasets download -d salader/dogs-vs-cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Unzipe the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unzip the downlaoded dataset\n",
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('dogs-vs-cats.zip', 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import tensorflow libraries for creating model and classification (CNN Model)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Assign lables, sample from data, set image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If `subset` is set, `validation_split` must be set, and inversely.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\OneDrive - Universiti Malaya\\Fahad bhai\\Project\\image_classification.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive%20-%20Universiti%20Malaya/Fahad%20bhai/Project/image_classification.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# generators\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive%20-%20Universiti%20Malaya/Fahad%20bhai/Project/image_classification.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_ds, validation_ds \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mimage_dataset_from_directory(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive%20-%20Universiti%20Malaya/Fahad%20bhai/Project/image_classification.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     directory \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive%20-%20Universiti%20Malaya/Fahad%20bhai/Project/image_classification.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     labels\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minferred\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive%20-%20Universiti%20Malaya/Fahad%20bhai/Project/image_classification.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     label_mode \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mint\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive%20-%20Universiti%20Malaya/Fahad%20bhai/Project/image_classification.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive%20-%20Universiti%20Malaya/Fahad%20bhai/Project/image_classification.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     image_size\u001b[39m=\u001b[39;49m(\u001b[39m256\u001b[39;49m,\u001b[39m256\u001b[39;49m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive%20-%20Universiti%20Malaya/Fahad%20bhai/Project/image_classification.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive%20-%20Universiti%20Malaya/Fahad%20bhai/Project/image_classification.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive%20-%20Universiti%20Malaya/Fahad%20bhai/Project/image_classification.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# validation_ds = keras.utils.image_dataset_from_directory(\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive%20-%20Universiti%20Malaya/Fahad%20bhai/Project/image_classification.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m#     directory = 'test',\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive%20-%20Universiti%20Malaya/Fahad%20bhai/Project/image_classification.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#     labels='inferred',\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive%20-%20Universiti%20Malaya/Fahad%20bhai/Project/image_classification.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#     image_size=(256,256)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive%20-%20Universiti%20Malaya/Fahad%20bhai/Project/image_classification.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# )\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\image_dataset.py:207\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    203\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m`color_mode` must be one of \u001b[39m\u001b[39m{\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrgb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrgba\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgrayscale\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m}. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    204\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived: color_mode=\u001b[39m\u001b[39m{\u001b[39;00mcolor_mode\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    205\u001b[0m     )\n\u001b[0;32m    206\u001b[0m interpolation \u001b[39m=\u001b[39m image_utils\u001b[39m.\u001b[39mget_interpolation(interpolation)\n\u001b[1;32m--> 207\u001b[0m dataset_utils\u001b[39m.\u001b[39;49mcheck_validation_split_arg(\n\u001b[0;32m    208\u001b[0m     validation_split, subset, shuffle, seed\n\u001b[0;32m    209\u001b[0m )\n\u001b[0;32m    211\u001b[0m \u001b[39mif\u001b[39;00m seed \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m     seed \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m1e6\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\dataset_utils.py:737\u001b[0m, in \u001b[0;36mcheck_validation_split_arg\u001b[1;34m(validation_split, subset, shuffle, seed)\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    733\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`validation_split` must be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    734\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreceived: \u001b[39m\u001b[39m{\u001b[39;00mvalidation_split\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    735\u001b[0m     )\n\u001b[0;32m    736\u001b[0m \u001b[39mif\u001b[39;00m (validation_split \u001b[39mor\u001b[39;00m subset) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m (validation_split \u001b[39mand\u001b[39;00m subset):\n\u001b[1;32m--> 737\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    738\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf `subset` is set, `validation_split` must be set, and inversely.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    739\u001b[0m     )\n\u001b[0;32m    740\u001b[0m \u001b[39mif\u001b[39;00m subset \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    741\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    742\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m`subset` must be either \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    743\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m or \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, received: \u001b[39m\u001b[39m{\u001b[39;00msubset\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    744\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: If `subset` is set, `validation_split` must be set, and inversely."
     ]
    }
   ],
   "source": [
    "# # generators\n",
    "# train_ds = keras.utils.image_dataset_from_directory(\n",
    "#     directory = 'train',\n",
    "#     labels='inferred',\n",
    "#     label_mode = 'int',\n",
    "#     batch_size=32,\n",
    "#     image_size=(256,256)\n",
    "# )\n",
    "\n",
    "\n",
    "# validation_ds = keras.utils.image_dataset_from_directory(\n",
    "#     directory = 'test',\n",
    "#     labels='inferred',\n",
    "#     label_mode = 'int',\n",
    "#     batch_size=32,\n",
    "#     image_size=(256,256)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Normalize the data values in betweeen 0 & 1 [0 - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "def process(image,label):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image,label\n",
    "\n",
    "train_ds = train_ds.map(process)\n",
    "validation_ds = validation_ds.map(process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create CNN model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,epochs=10,validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'],color='red',label='train')\n",
    "plt.plot(history.history['val_accuracy'],color='blue',label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],color='red',label='train')\n",
    "plt.plot(history.history['val_accuracy'],color='blue',label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],color='red',label='train')\n",
    "plt.plot(history.history['val_loss'],color='blue',label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],color='red',label='train')\n",
    "plt.plot(history.history['val_loss'],color='blue',label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
